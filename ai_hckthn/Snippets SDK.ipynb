{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippets SDK\n",
    "\n",
    "\n",
    "We store our subscriptions inside a dictionary: `subscriptions_dict`.\n",
    "\n",
    "The APIs return a lot of crap. The JSON responses are saved as dictionaries. From there, I tried to access some 'useful' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializer \n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import json\n",
    "import os, requests\n",
    "import numpy as np\n",
    "\n",
    "# Initializer\n",
    "# Subscriptions\n",
    "subscriptions_dict = {'computer_vision':'c0fd5de0a7eb4ad9a241d1fe1f4cd989',\n",
    "                      'face_api': 'cd91c79a18534dc58d7eae4608ea3d3d',\n",
    "                      'speech_api': 'd3015735e75546cd9af885976b8e4c54',\n",
    "                      'text_analytics': 'bcf64cde5aad4e09856471aa6530026f',\n",
    "                      'luis':'2a2b546798854097ace2140bf961a493'}\n",
    "\n",
    "# Request Headers\n",
    "headers = {'Content-Type': 'applications/json',\n",
    "            'Ocp-Apim-Subscription-Key': subscriptions_dict['computer_vision']}\n",
    "\n",
    "# Content body to be sent, many forms, to be redefined\n",
    "body = \"{'url':'https://pbs.twimg.com/profile_images/1062098998746644480/JTIpfWME_400x400.jpg'}\"\n",
    "# _ _ _ _  _ _ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying requests\n",
    "\n",
    "Two global variables to be used for all the requests:\n",
    "\n",
    "- `body` : many forms, depends on the API\n",
    "- `headers`: dict with two keys: \n",
    "    - the content type: 'application/json' or 'application/octet-stream'.\n",
    "    - the API key of your resource.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target body for is changed using these two functions\n",
    "def change_headers(contentType='application/json', api='computer_vision'):\n",
    "    '''At the beginning of every function to ensure proper settings'''\n",
    "    global headers\n",
    "    headers = {'Content-Type': contentType,\n",
    "               'Ocp-Apim-Subscription-Key':subscriptions_dict[api]}\n",
    "\n",
    "# Camera for Pi\n",
    "# Takes picture by calling the raspistill command in the terminal and defines it as body\n",
    "def body_take_picture(name='me.png'):\n",
    "    \"\"\"defines body as binary image data of the picture taken, \n",
    "       required for comptuer vision api\"\"\"\n",
    "    global body, headers\n",
    "    headers['Content-Type'] = 'application/octet-stream'\n",
    "    os.system('raspistill -o {}'.format(\"/home/pi/Robuzure/{}.png\".format(name)))\n",
    "    body = open('/home/pi/Robuzure/{}.png'.format(name), 'rb')\n",
    "\n",
    "# For Test in PC\n",
    "def body_url_image(url='https://pbs.twimg.com/profile_images/1062098998746644480/JTIpfWME_400x400.jpg'):\n",
    "    global headers, body\n",
    "    headers['Content-Type'] = 'application/json'\n",
    "    body = \"{'url':'%s'}\"%url\n",
    "    return body\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'url':'https://pbs.twimg.com/profile_images/1062098998746644480/JTIpfWME_400x400.jpg'}\""
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This defines body as a dictionary for application/json requests for CV: URL based\n",
    "body_url_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'url':'https://pbs.twimg.com/profile_images/1062098998746644480/JTIpfWME_400x400.jpg'}\""
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use different APIs in the same environment without errors, I made the `change_headers` function to specify what `contentType` and `api` to use. The `api` argument access your key from the resource `subscriptions_dict[api]`.\n",
    "\n",
    "When changing from one API to another, use `change_headers` to configure the request correctly.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "# Configure the head of the request for ComputerVision and URL based images\n",
    "change_headers(contentType='application/json',api='computer_vision')\n",
    "# Define global `body` as a dictionary {'url':'https...'} \n",
    "body_url_image(url='https://pbs.twimg.com/profile_images/1062098998746644480/JTIpfWME_400x400.jpg')\n",
    "# call a functions from the CV API, using `body`\n",
    "describe_image(body, number_of_descriptions=3)\n",
    "\n",
    "```\n",
    "\n",
    "**In the Pi**, the function `body_take_picture` tells the pi to take a picture and  define it as the global `body` (as binary image data). The global body can be then sent to the APIs:\n",
    "\n",
    "```python\n",
    "# Configure the head of the request for Computer Vision and binary image data\n",
    "change_headers(contentType='application/octet-stream', api='computer_vision')\n",
    "# Define global body as binary image data from the image me.png\n",
    "body_take_picture(name='me.png') \n",
    "# call function from the CV API, using body\n",
    "describe_image(body, number_of_descriptions=3)\n",
    "```\n",
    "\n",
    "\n",
    "> I really hope this is not too convoluted. Check the examples below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision and Face API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_image(img, number_of_descriptions=1):\n",
    "    '''Returns a number_of_descriptions from an image'''\n",
    "    params = urllib.parse.urlencode({\n",
    "    # Request parameters\n",
    "    'maxCandidates': \"{}\".format(number_of_descriptions),\n",
    "    'language': 'en'})\n",
    "\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection('westeurope.api.cognitive.microsoft.com')\n",
    "        # img recieves the binary image (body)\n",
    "        conn.request(\"POST\", \"/vision/v2.0/describe?%s\" % params, img, headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        r = json.loads(data.decode())\n",
    "        \n",
    "        for i in range(len(r['description']['captions'])):\n",
    "            print(r['description']['captions'][i]['text'])\n",
    "\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person standing in front of a large rock\n",
      "a person standing on a rock\n",
      "a person standing on a rock\n",
      "a person standing in front of a rock\n"
     ]
    }
   ],
   "source": [
    "# redefines body\n",
    "body_url_image(url='https://pbs.twimg.com/profile_images/1062098998746644480/JTIpfWME_400x400.jpg')\n",
    "# set up headers\n",
    "change_headers(contentType='application/json', api='computer_vision')\n",
    "# function using body\n",
    "describe_image(body, number_of_descriptions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img):\n",
    "    ''''''\n",
    "    global found_objects\n",
    "    found_objects = []\n",
    "    params = urllib.parse.urlencode({})\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection('westeurope.api.cognitive.microsoft.com')\n",
    "        conn.request(\"POST\", \"/vision/v2.0/detect?%s\" % params, body, headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        r = json.loads(data.decode())\n",
    "        #print(data)\n",
    "        print(r.keys())\n",
    "        print(\"In the image of size {} by {} pixels, {} objects were detected\".format(r['metadata']['width'], r['metadata']['height'], \n",
    "                                                                                      len(r['objects']))) \n",
    "        for i in r['objects']:\n",
    "            # acessing the rectangle key\n",
    "            found_objects.append(i['object'])\n",
    "            print('{} detected at region {}'.format(i['object'], i['rectangle']))\n",
    "        # print(found_objects) can be read by speaker\n",
    "        # DRAW BOUNDING BOXES into Image with CV2?\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n",
    "\n",
    "change_headers(api='computer_vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['objects', 'requestId', 'metadata'])\n",
      "In the image of size 400 by 400 pixels, 3 objects were detected\n",
      "tree detected at region {'x': 75, 'y': 2, 'w': 68, 'h': 93}\n",
      "headwear detected at region {'x': 130, 'y': 71, 'w': 117, 'h': 68}\n",
      "person detected at region {'x': 93, 'y': 70, 'w': 284, 'h': 329}\n"
     ]
    }
   ],
   "source": [
    "# To analyze the same image in the same api, no need to redefine body or headers\n",
    "detect_objects(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(img, visualFeatures='Description, Categories, Faces'):\n",
    "    '''visualFeatures: a string of comma separated keywords 'Brands, Adult, Objects'\n",
    "       Category of Image\n",
    "       Tags of the image'''\n",
    "    global speak\n",
    "    change_headers(api='computer_vision')\n",
    "    params = urllib.parse.urlencode({\n",
    "        # Request parameters\n",
    "        'visualFeatures': '{}'.format(visualFeatures),\n",
    "        'details': '',\n",
    "        'language': 'en'})\n",
    "\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection('westeurope.api.cognitive.microsoft.com')\n",
    "        conn.request(\"POST\", \"/vision/v2.0/analyze?%s\" % params, img, headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        r = json.loads(data.decode())\n",
    "\n",
    "        # Handling Response in some useful manner. JSON has a lot of keys.\n",
    "        if r['faces'] == []:\n",
    "            print('No faces encountered')\n",
    "        else:\n",
    "            print('At least a face was detected')\n",
    "        print(\"Category of image: {}\".format(r['categories'][0]['name']))\n",
    "        \n",
    "        # extracting tags\n",
    "        print(\"Tags found in the image {}\".format(r['description']['tags']))\n",
    "        # send to some text generator service\n",
    "\n",
    "        if \"Description\" in visualFeatures:\n",
    "            speak = (r['description']['captions'][0]['text'])\n",
    "\n",
    "        print(speak)\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least a face was detected\n",
      "Category of image: people_\n",
      "Tags found in the image ['outdoor', 'person', 'rock', 'young', 'woman', 'holding', 'man', 'standing', 'hat', 'smiling', 'wearing', 'boy', 'riding', 'snow', 'walking', 'large', 'rocky', 'park', 'dirt', 'board', 'playing', 'skiing']\n",
      "a person standing in front of a large rock\n"
     ]
    }
   ],
   "source": [
    "# no need to redefine headers or body\n",
    "analyze_image(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    global info\n",
    "    \n",
    "    \"\"\"Find attributes of a human face age, gender, emotions etc.\"\"\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        # Request parameters\n",
    "        'returnFaceId': 'true',\n",
    "        'returnFaceLandmarks': 'false',\n",
    "        'returnFaceAttributes': 'age,gender,smile,facialHair,glasses,emotion,hair',\n",
    "        'recognitionModel': 'recognition_01',\n",
    "        'returnRecognitionModel': 'false',\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection('westeurope.api.cognitive.microsoft.com')\n",
    "        conn.request(\"POST\", \"/face/v1.0/detect?%s\" % params, img, headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        conn.close()\n",
    "        #print(data)\n",
    "        r = json.loads(data.decode())\n",
    "    \n",
    "        print('{} face(s) were found'.format(len(r)))\n",
    "\n",
    "        for face_info in r:\n",
    "            attributes = face_info['faceAttributes']\n",
    "            #print(\"Face Info \", attributes, '\\n')\n",
    "            highest_emotion_index = np.argmax(list(attributes['emotion'].values()))\n",
    "            #print(highest_emotion_index)\n",
    "            info = \"A {} of around {} years with a {} of {} percent\".format(attributes['gender'], \n",
    "                                                                            attributes['age'], \n",
    "                                                                            list(attributes['emotion'].keys())[highest_emotion_index],\n",
    "                                                                           int(max(attributes['emotion'].values())*100))\n",
    "            print(info)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 face(s) were found\n",
      "A male of around 33.0 years with a happiness of 100 percent\n"
     ]
    }
   ],
   "source": [
    "# Now we need to change the api from computer_vision to face_api so we redefine headers\n",
    "# the body is the same, as we want to analyze the same image\n",
    "change_headers(contentType='application/json',api='face_api')\n",
    "detect_face(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics\n",
    "\n",
    "The function `text_body` redefines `body` in the correct format to send to the Text Analytics API. I put inside the functions for convenience. The `body` variable is redefined with the `text` argument of the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextToAnalyze = 'Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\\nNow we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battlefield of that war.\\nWe have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\\nBut, in a larger sense, we can not dedicate, we can not consecrate, we can not hallow this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract.\\nThe world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced.\\nIt is rather for us to be here dedicated to the great task remaining before us that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion, that we here highly resolve that these dead shall not have died in vain; that this nation, under God, shall have a new birth of freedom and that government of the people, by the people, for the people, shall not perish from the earth.'\n",
    "\n",
    "def text_body(TextToAnalyze=TextToAnalyze):\n",
    "    \"\"\"To create a body of a single text to be analyzed. The (same Id to track more documents)\"\"\"\n",
    "    global body\n",
    "    body = {\n",
    "        # to this list you can add more dictionaries {lang, id, text..} to analyze more than one text\n",
    "      \"documents\": [\n",
    "        {\n",
    "            \"id\": \"TextTest\",\n",
    "            \"text\": \"'{}'\".format(TextToAnalyze)\n",
    "        }]}\n",
    "    \n",
    "text_body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    '''Only for one '''\n",
    "    textAnalyticsURI = 'westeurope.api.cognitive.microsoft.com'\n",
    "    change_headers(api='text_analytics')\n",
    "    params = urllib.parse.urlencode({})\n",
    "    text_body(text)\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection(textAnalyticsURI)\n",
    "        conn.request(\"POST\", \"/text/analytics/v2.0/languages?%s\" % params, str(body), headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        r = json.loads(data.decode())\n",
    "        print(r['documents'][0]['detectedLanguages'][0]['name'])\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalan\n"
     ]
    }
   ],
   "source": [
    "change_headers(contentType='application/json',api='text_analytics')\n",
    "# Redefines body and calls function\n",
    "detect_language(text='bon dia com et dius?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_phrases(text):\n",
    "    # Define the parameters\n",
    "    textAnalyticsURI = 'westeurope.api.cognitive.microsoft.com'\n",
    "    change_headers(api='text_analytics')\n",
    "    params = urllib.parse.urlencode({})\n",
    "    text_body(text)\n",
    "    try:\n",
    "        # Execute the REST API call and get the response.\n",
    "        conn = http.client.HTTPSConnection(textAnalyticsURI)\n",
    "        conn.request(\"POST\", \"/text/analytics/v2.0/keyPhrases?%s\" % params, str(body), headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read().decode(\"UTF-8\")\n",
    "\n",
    "        # 'data' contains the JSON response, which includes a collection of documents.\n",
    "        parsed = json.loads(data)\n",
    "        for document in parsed['documents']:\n",
    "            print(\"Document \" + document[\"id\"] + \" key phrases:\")\n",
    "            for phrase in document['keyPhrases']:\n",
    "                print(\"  \" + phrase)\n",
    "            print(\"---------------------------\")\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error:')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document TextTest key phrases:\n",
      "  fathers\n",
      "  proposition\n",
      "  continent\n",
      "  Liberty\n",
      "  new nation\n",
      "  great civil war\n",
      "  score\n",
      "  years\n",
      "  men\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# redefines body, same headers as before\n",
    "key_phrases('Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.Now we are engaged in a great civil war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentiment(text):\n",
    "     # Define the parameters\n",
    "    textAnalyticsURI = 'westeurope.api.cognitive.microsoft.com'\n",
    "    change_headers(api='text_analytics')\n",
    "    params = urllib.parse.urlencode({})\n",
    "    text_body(text)\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection(textAnalyticsURI)\n",
    "        conn.request(\"POST\", \"/text/analytics/v2.0/sentiment?%s\" % params, str(body), headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read().decode(\"UTF-8\")\n",
    "        parsed = json.loads(data) \n",
    "        # Get the numeric score for each document\n",
    "        for document in parsed['documents']:\n",
    "            sentiment = \"negative\"\n",
    "            # if it's more than 0.5, consider the sentiment to be positive.\n",
    "            if document[\"score\"] >= 0.5:\n",
    "                sentiment = \"positive\"\n",
    "            print(\"Document:\" + document[\"id\"] + \" = \" + sentiment)\n",
    "        conn.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:TextTest = positive\n"
     ]
    }
   ],
   "source": [
    "# redefines body\n",
    "check_sentiment('Actually pretty normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:TextTest = negative\n"
     ]
    }
   ],
   "source": [
    "check_sentiment('Good but not so amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:TextTest = negative\n"
     ]
    }
   ],
   "source": [
    "check_sentiment('Good. Bad. Bad. Good. Bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:TextTest = positive\n"
     ]
    }
   ],
   "source": [
    "check_sentiment('Interesting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entities(body):\n",
    "    params = urllib.parse.urlencode({\n",
    "    })\n",
    "    textAnalyticsURI = 'westeurope.api.cognitive.microsoft.com'\n",
    "    change_headers(api='text_analytics')\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection('westeurope.api.cognitive.microsoft.com')\n",
    "        conn.request(\"POST\", \"/text/analytics/v2.0/entities?%s\" % params, str(body), headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        print(data)\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"documents\":[{\"id\":\"TextTest\",\"entities\":[{\"name\":\"Conceived in Liberty\",\"matches\":[{\"text\":\"conceived in Liberty\",\"offset\":91,\"length\":20}],\"wikipediaLanguage\":\"en\",\"wikipediaId\":\"Conceived in Liberty\",\"wikipediaUrl\":\"https://en.wikipedia.org/wiki/Conceived_in_Liberty\",\"bingId\":\"9540782b-ef0a-caed-5657-9706c6b8ce02\"},{\"name\":\"Earth\",\"matches\":[{\"text\":\"earth\",\"offset\":1450,\"length\":5}],\"wikipediaLanguage\":\"en\",\"wikipediaId\":\"Earth\",\"wikipediaUrl\":\"https://en.wikipedia.org/wiki/Earth\",\"bingId\":\"6ddb3372-4801-5567-321e-e8a53bd774a4\"},{\"name\":\"God\",\"matches\":[{\"text\":\"God\",\"offset\":1319,\"length\":3}],\"wikipediaLanguage\":\"en\",\"wikipediaId\":\"God\",\"wikipediaUrl\":\"https://en.wikipedia.org/wiki/God\",\"bingId\":\"d38371fb-8068-3139-6cb8-e9cfe3118da0\"}]}],\"errors\":[]}'\n"
     ]
    }
   ],
   "source": [
    "find_entities(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech API\n",
    "\n",
    "The Speech API is a bit different. It requires you to **have an access token**, each one is valid for 10 minutes [ ! ].\n",
    "\n",
    "You can request an access token like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the API key to request an access token\n",
    "response = requests.post('https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issueToken', headers=headers)\n",
    "accesstoken = str(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `speech_to_text` function receives the path of a wav file and outputs the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(path_to_wav):\n",
    "    '''Input a wav file, returns text'''\n",
    "    change_headers(api='speech_api')\n",
    "    with open(\"{}\".format(path_to_wav), mode=\"rb\") as audio_file:\n",
    "        audio_data =  audio_file.read()\n",
    "    \n",
    "    # Now that we have a token, we can set up the request\n",
    "    speechToTextEndPoint = \"https://westeurope.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1\"\n",
    "    headers = {\"Content-type\": \"audio/wav; codec=audio/pcm; samplerate=16000\", \n",
    "            \"Authorization\": \"Bearer \" + accesstoken}\n",
    "    params = {\"language\":\"en-US\"}\n",
    "    body = audio_data\n",
    "\n",
    "    # Connect to server, post the request, and get the result\n",
    "    response = requests.post(speechToTextEndPoint,data=body, params=params, headers=headers)\n",
    "    result = str(response.text)\n",
    "    print(json.loads(result)['DisplayText'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rain in Spain stays mainly in the plain.\n"
     ]
    }
   ],
   "source": [
    "change_headers(contentType='application/json', api='speech_api')\n",
    "speech_to_text('/Users/jdchipox/Downloads/DAT263x-demos/Text and Speech/RainSpain.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [LUIS for Language Understanding](https://azure.microsoft.com/en-us/services/cognitive-services/language-understanding-intelligent-service/)\n",
    "\n",
    "- [Really cool stuff](https://www.luis.ai/welcome)\n",
    "\n",
    "- Get intent! We can use it to take pictures, record audio!\n",
    "\n",
    "I created a very simple model with two intents: \n",
    "    - Take Picture\n",
    "    - Record Audio\n",
    "    \n",
    "Then I gave a couple of phrases that specify one intent or the other. Such as:\n",
    "- `what do you see?` => Take a picture\n",
    "- `listen to me` => Record Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(text):\n",
    "    import requests\n",
    "    params ={\n",
    "        # Query parameter\n",
    "        'q': ''.format(text),\n",
    "        # Optional request parameters, set to default values\n",
    "        'timezoneOffset': '0',\n",
    "        'verbose': 'false',\n",
    "        'spellCheck': 'false',\n",
    "        'staging': 'false',\n",
    "        'subscription-key':'1b91b846370b41e8b9277ab927fb558c'}\n",
    "\n",
    "    try:\n",
    "\n",
    "        #r = requests.get('https://westeurope.api.cognitive.microsoft.com/luis/v2.0/apps/df46b650-b9f9-4489-b9f8-74532e9fd247',headers=headers, params=params)\n",
    "        r = requests.get('https://westus.api.cognitive.microsoft.com/luis/v2.0/apps/df46b650-b9f9-4489-b9f8-74532e9fd247?verbose=true&timezoneOffset=-360&subscription-key=1b91b846370b41e8b9277ab927fb558c&q={}'.format(text))\n",
    "        r = json.loads((r.content).decode())\n",
    "        print(r['topScoringIntent'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'Take Picture', 'score': 0.9801855}\n"
     ]
    }
   ],
   "source": [
    "change_headers(contentType='application/json', api='luis')\n",
    "get_intent('Take a picture with the camera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'Record Audio', 'score': 0.931635}\n"
     ]
    }
   ],
   "source": [
    "get_intent('Record my voice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- Create a function that records audio in the Raspberry Pi.\n",
    "- Chain functions together for useful purposes. For example, after recording a wav file as 'audio.wav' with the pi we can use `speech_to_text` to extract the text and then pass this to `get_intent` to get the intention we want, for example Take a Picture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippets SDK\n",
    "\n",
    "## Subscriptions\n",
    "\n",
    "We store our Azure Subscriptions inside a dictionary.\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "The APIs return a lot of crap. The JSON responses are saved as dicionaries. I tried to access some 'useful' information.\n",
    "\n",
    "## Computer Vision API\n",
    "### Input\n",
    "\n",
    "The Pi takes a picture with:\n",
    "```python\n",
    " os.system('raspistill -o {}'.format(\"/home/pi/SavedImg.png\"))\n",
    "```\n",
    "\n",
    "The image is given as binary data inside the body:\n",
    "\n",
    "```python\n",
    "body = open('/home/pi/SavedImg.png', 'rb')\n",
    "```\n",
    "\n",
    "### Functions\n",
    "```python\n",
    "describe_image(body, number_of_descriptions=3)`\n",
    "```\n",
    "```\n",
    "a crowded city street filled with traffic at night.\n",
    "a group of people on a city street filled with traffic at night.\n",
    "a close up of a busy city street filled with traffic at night.\n",
    "```\n",
    "___\n",
    "```python\n",
    "detect_objects(body)\n",
    "```\n",
    "```\n",
    "In the image of size 1826 by 2436 pixels, 5 objects were detected> taxi detected at region {'x': 1277, 'y': 2057, 'w': 363, 'h': 231}\n",
    "person detected at region {'x': 0, 'y': 2222, 'w': 174, 'h': 213}\n",
    "person detected at region {'x': 199, 'y': 2224, 'w': 299, 'h': 206}\n",
    "person detected at region {'x': 434, 'y': 2176, 'w': 236, 'h': 251}\n",
    "person detected at region {'x': 826, 'y': 2161, 'w': 255, 'h': 270}\n",
    "\n",
    "# Would be cool to draw the boxes in the images\n",
    "```\n",
    "___\n",
    "```python\n",
    "analyze_image(body)\n",
    "```\n",
    "```\n",
    "No faces encountered\n",
    "Category of image: outdoor_street\n",
    "Tags found in the image: ['outdoor', 'building', 'street', 'city', 'busy', 'traffic', 'filled', 'people', 'car', 'walking', 'many', 'crowded', 'bunch', 'group', 'night', 'large', 'table', 'light', 'man', 'standing', 'umbrella', 'riding', 'tall', 'sign', 'rain', 'road']\n",
    "\n",
    "a crowded city street filled with traffic at night\n",
    "```\n",
    "## Face API\n",
    "Receives the same type of `body` as before.\n",
    "\n",
    "```python\n",
    "face_detect(body)\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Speech \n",
    "```python\n",
    "speech_to_text('</Users/jdchipox/Downloads/DAT263x-demos/Text and Speech/RainSpain.wav>')\n",
    "```\n",
    "```\n",
    "The rain in Spain stays mainly in the plain.\n",
    "```\n",
    "\n",
    "## Text Analytics\n",
    "\n",
    "We need to give the text inside a dictionary as follows:\n",
    "\n",
    "### Input\n",
    "```python\n",
    "TextToAnalyze = 'Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty...'\n",
    "\n",
    "body = {\n",
    "  \"documents\": [\n",
    "    {\n",
    "        \"id\": \"TextTest\",\n",
    "        \"text\": \"'{}'\".format(TextToAnalyze)\n",
    "    }]}\n",
    "```\n",
    "### Functions\n",
    "```python\n",
    "detect_language(body)\n",
    "```\n",
    "```\n",
    "English\n",
    "```\n",
    "___\n",
    "```python\n",
    "find_entities(body)\n",
    "# still unprocessed result\n",
    "```\n",
    "```\n",
    "b'{\"documents\":[{\"id\":\"TextTest\",\"entities\":[{\"name\":\"Conceived in Liberty\",\"matches\":[{\"text\":\"conceived in Liberty\",\"offset\":91,\"length\":20}],\"wikipediaLanguage\":\"en\",\"wikipediaId\":\"Conceived in Liberty\",\"wikipediaUrl\":\"https://en.wikipedia.org/wiki/Conceived_in_Liberty\",\"bingId\":\"9540782b-ef0a-caed-5657-9706c6b8ce02\"},{\"name\":\"Earth\",\"matches\":[{\"text\":\"earth\",\"offset\":1450,\"length\":5}],\"wikipediaLanguage\":\"en\",\"wikipediaId\":\"Earth\",\"wikipediaUrl\":\"https://en.wikipedia.org/wiki/Earth\",\"bingId\":\"6ddb3372-4801-5567-321e-e8a53bd774a4\"},{\"name\":\"God\",\"matches\":[{\"text\":\"God\",\"offset\":1319,\"length\":3}],\"wikipediaLanguage\":\"en\",\"wikipediaId\":\"God\",\"wikipediaUrl\":\"https://en.wikipedia.org/wiki/God\",\"bingId\":\"d38371fb-8068-3139-6cb8-e9cfe3118da0\"}]}],\"errors\":[]}'\n",
    "```\n",
    "____\n",
    "\n",
    "```python\n",
    "key_phrases(body)\n",
    "```\n",
    "```\n",
    "  new nation\n",
    "  people\n",
    "  honored dead\n",
    "  great civil war\n",
    "  great battlefield\n",
    "  great task\n",
    "  living\n",
    "  increased devotion\n",
    "  measure of devotion\n",
    "  brave men\n",
    "  new birth of freedom\n",
    "  government\n",
    "  fathers\n",
    "  final resting place\n",
    "  proposition\n",
    "  continent\n",
    "  Liberty\n",
    "  God\n",
    "  world\n",
    "  little note\n",
    "  score\n",
    "  years\n",
    "  cause\n",
    "  larger sense\n",
    "  poor power\n",
    "  unfinished work\n",
    "  portion\n",
    "  lives\n",
    "  ground\n",
    "  earth\n",
    "```\n",
    "\n",
    "```python\n",
    "check_sentiment(body)\n",
    "```\n",
    "```\n",
    "Document:TextTest = positive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
